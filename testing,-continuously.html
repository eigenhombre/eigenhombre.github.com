<head><title>Testing, Continuously</title><link href="tufte-css/tufte.css" rel="stylesheet" /><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script></head><body><h1>Testing, Continuously</h1><p class="subtitle">John Jacobsen</p><div><p><strong>This is the fourth post in a series about Clojure workflows.</strong></p><p>In my last post, I laid out a workflow based on TDD but with the
  addition of &ldquo;literate programming&rdquo; (writing prose interleaved with
  code) and experimentation at the REPL. Here I dive a bit deeper into
  my test setup.</p><p><span>Even before I started developing in Clojure full time, I
  <a href="http://eigenhombre.com/testing/2012/03/31/ontinuous-testing-in-python-clojure-and-blub/">discovered</a>
  that creating a configuration that provides near-instant test
  feedback made me more efficient as a developer. <strong>I expect to be able to run all relevant tests every time I
  hit the &ldquo;Save&rdquo; button</strong> on any file in my project, and to see the
  results within &ldquo;a few&rdquo; (preferrably, less than 3-4) seconds. Some
  examples of systems which provide this are:</span></p><p><ol><li>Ruby-based <a href="https://github.com/guard/guard#readme">Guard</a>, commonly used in the Rails community;</li><li><a href="https://github.com/eigenhombre/continuous-testing-helper">Conttest</a>, a language-agnostic Python-based test runner I wrote;</li><li>in the Clojure sphere:<ol><li><a href="https://github.com/marick/Midje">Midje</a>,
     using the <code>:autotest</code> option;</li><li>Expectations, using the autoexpect plugin for Leiningen;</li><li><a href="https://github.com/slagyr/speclj">Speclj</a>,
     using the <code>-a</code> option;</li><li>clojure.test, with <a href="https://github.com/jakepearson/quickie">quickie</a> (and
     possibly other) plugins</li></ol></li></ol></p><p><span>I used to use Expectations; then, for a long time I liked Midje for
  its rich DSL and the ability to develop functionality bottom-up or
  <a href="https://github.com/marick/Midje/wiki/The-idea-behind-top-down-development">top-down</a>.  Now, I pretty much just use Speclj because it&rsquo;s
     autotest reloader is the most reliable and trouble-free.</span></p><p>(Earlier versions of this post had details for setting up Midje,
  now omitted &mdash; see the Speclj docs to get started.)</p><p>Running your tests hundreds of times per day not only reduces
  debugging time (you generally can figure out exactly what you broke
  much easier when the deltas to the code since the last successful
  test are small), but they also help build knowledge of what parts of
  the code run slowly. If the tests start taking longer than a few
  seconds to run, I like to give some thought to what could be
  improved &mdash; either I am focusing my testing effort at too high of a
  level (e.g. hitting the database, starting/stopping subprocesses,
  etc.) or I have made some questionable assumptions about performance
  somewhere.</p><p>Sometimes, however, despite best efforts, the tests still take
  longer than a few seconds to run. At this point I start annotating
  tests with metadata indicating that those tests should be skipped
  during autotesting (I still run the full test suite before
  committing (usually) or pushing to master (always)).  In this way, I
  can continue to get the most feedback in real time as possible &mdash;
  which helps me develop quality code efficiently. The exact
  mechanism for skipping slow tests depends on the test library you&rsquo;re
  using; I haven&rsquo;t had to do it with Speclj yet.</p><p>In the next post, we&rsquo;ll switch gears and talk about literate
  programming with Marginalia.</p></div></body><div><p><a href="about.html">about</a>|<a href="content.html">all posts</a></p><p>&copy; 2015 <a href="about.html">John Jacobsen</a>. Created with <a href="https://github.com/eigenhombre/unmark">unmark</a>.  CSS by <a href="https://edwardtufte.github.io/tufte-css/">Tufte-CSS</a>.</p></div>